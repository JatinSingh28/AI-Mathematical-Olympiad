{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8008788,"sourceType":"datasetVersion","datasetId":4717118},{"sourceId":8023365,"sourceType":"datasetVersion","datasetId":4728129}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jatinsinghsagoi/aimo-24-finetune-deepseek-math?scriptVersionId=172801531\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Fine-Tuning Deepseek-math with Bits and Bytes, and QLoRA\n\nToday we'll explore fine-tuning the Deepseek-math model available on Kaggle Models using QLoRA, Bits and Bytes, and PEFT.\n\n- QLoRA: [Quantized Low Rank Adapters](https://arxiv.org/pdf/2305.14314.pdf) - this is a method for fine-tuning LLMs that uses a small number of quantized, updateable parameters to limit the complexity of training. This technique also allows those small sets of parameters to be added efficiently into the model itself, which means you can do fine-tuning on lots of data sets, potentially, and swap these \"adapters\" into your model when necessary.\n- [Bits and Bytes](https://github.com/TimDettmers/bitsandbytes): An excellent package by Tim Dettmers et al., which provides a lightweight wrapper around custom CUDA functions that make LLMs go faster - optimizers, matrix mults, and quantization. In this notebook we'll be using the library to load our model as efficiently as possible.\n- [PEFT](https://github.com/huggingface/peft): An excellent Huggingface library that enables a number Parameter Efficient Fine-tuning (PEFT) methods, which again make it less expensive to fine-tune LLMs - especially on more lightweight hardware like that present in Kaggle notebooks.\n\nMany thanks to [Bojan Tunguz](https://www.kaggle.com/tunguz) for his excellent [Jeopardy dataset](https://www.kaggle.com/datasets/tunguz/200000-jeopardy-questions)!\n\nThis notebook is based on [an excellent example from LangChain](https://github.com/asokraju/LangChainDatasetForge/blob/main/Finetuning_Falcon_7b.ipynb).","metadata":{}},{"cell_type":"markdown","source":"## Package Installation\n\nNote that we're loading very specific versions of these libraries. Dependencies in this space can be quite difficult to untangle, and simply taking the latest version of each library can lead to conflicting version requirements. It's a good idea to take note of which versions work for your particular use case, and `pip install` them directly.","metadata":{"id":"wIa8WRIHvuZy"}},{"cell_type":"code","source":"# !pip install -qqq bitsandbytes==0.39.0\n# !pip install -qqq torch==2.0.1\n# !pip install -qU git+https://github.com/huggingface/transformers\n# !pip install -qqq -U git+https://github.com/huggingface/peft.git@42a184f\n# !pip install -qqq -U git+https://github.com/huggingface/accelerate.git\n# !pip install -qqq datasets==2.12.0\n!pip install -qqq loralib==0.1.1\n!pip install -qqq einops==0.6.1","metadata":{"id":"g3agEMJEnKsl","outputId":"56ab843a-e9c8-4158-8c04-18d77aec44fd","_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-19T06:19:27.927057Z","iopub.execute_input":"2024-04-19T06:19:27.927903Z","iopub.status.idle":"2024-04-19T06:19:51.7657Z","shell.execute_reply.started":"2024-04-19T06:19:27.927869Z","shell.execute_reply":"2024-04-19T06:19:51.764646Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers accelerate peft datasets bitsandbytes torch","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:19:51.768225Z","iopub.execute_input":"2024-04-19T06:19:51.768585Z","iopub.status.idle":"2024-04-19T06:20:03.850453Z","shell.execute_reply.started":"2024-04-19T06:19:51.768557Z","shell.execute_reply":"2024-04-19T06:20:03.849307Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.22.0)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.10.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport os\nfrom pprint import pprint\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import load_dataset, Dataset\nimport wandb\nfrom huggingface_hub import notebook_login\n\nfrom transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import LoraConfig, PeftConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"","metadata":{"id":"dv3aJo8Anhyw","outputId":"66f7b274-28a9-45b4-c0e6-d25194424594","execution":{"iopub.status.busy":"2024-04-19T06:20:03.852188Z","iopub.execute_input":"2024-04-19T06:20:03.852478Z","iopub.status.idle":"2024-04-19T06:20:03.859313Z","shell.execute_reply.started":"2024-04-19T06:20:03.852451Z","shell.execute_reply":"2024-04-19T06:20:03.858236Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Loading and preparing our model\n\nWe're going to use the Deepseek-math model for our test. We'll be using Bits and Bytes to load it in 4-bit format, which should reduce memory consumption considerably, at a cost of some accuracy.\n\nNote the parameters in `BitsAndBytesConfig` - this is a fairly standard 4-bit quantization configuration, loading the weights in 4-bit format, using a straightforward format (`normal float 4`) with double quantization to improve QLoRA's resolution. The weights are converted back to `bfloat16` for weight updates, then the extra precision is discarded.","metadata":{"id":"AgqJriqjwMyK"}},{"cell_type":"code","source":"# !pip install -qU git+https://github.com/huggingface/transformers","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:20:03.860658Z","iopub.execute_input":"2024-04-19T06:20:03.860999Z","iopub.status.idle":"2024-04-19T06:20:03.876259Z","shell.execute_reply.started":"2024-04-19T06:20:03.860966Z","shell.execute_reply":"2024-04-19T06:20:03.87536Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model = \"/kaggle/input/deepseek-math\"\nMODEL_NAME = model\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    quantization_config=bnb_config\n)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"id":"mllA2Ka_ol13","execution":{"iopub.status.busy":"2024-04-19T06:20:03.879386Z","iopub.execute_input":"2024-04-19T06:20:03.879671Z","iopub.status.idle":"2024-04-19T06:20:17.316257Z","shell.execute_reply.started":"2024-04-19T06:20:03.879646Z","shell.execute_reply":"2024-04-19T06:20:17.315201Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"887d58e641924af58bcb221f63a93344"}},"metadata":{}}]},{"cell_type":"markdown","source":"Below, we'll use a nice PEFT wrapper to set up our model for training / fine-tuning. Specifically this function sets the output embedding layer to allow gradient updates, as well as performing some type casting on various components to ensure the model is ready to be updated.","metadata":{}},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)","metadata":{"id":"na8DUq4IoqpB","execution":{"iopub.status.busy":"2024-04-19T06:20:17.317624Z","iopub.execute_input":"2024-04-19T06:20:17.317921Z","iopub.status.idle":"2024-04-19T06:20:17.332849Z","shell.execute_reply.started":"2024-04-19T06:20:17.317896Z","shell.execute_reply":"2024-04-19T06:20:17.331886Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Below, we define some helper functions - their purpose is to properly identify our update layers so we can... update them!","metadata":{}},{"cell_type":"code","source":"import re\ndef get_num_layers(model):\n    numbers = set()\n    for name, _ in model.named_parameters():\n        for number in re.findall(r'\\d+', name):\n            numbers.add(int(number))\n    return max(numbers)\n\ndef get_last_layer_linears(model):\n    names = []\n    \n    num_layers = get_num_layers(model)\n    for name, module in model.named_modules():\n        if str(num_layers) in name and not \"encoder\" in name:\n            if isinstance(module, torch.nn.Linear):\n                names.append(name)\n    return names","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:20:17.33384Z","iopub.execute_input":"2024-04-19T06:20:17.334105Z","iopub.status.idle":"2024-04-19T06:20:17.341192Z","shell.execute_reply.started":"2024-04-19T06:20:17.334061Z","shell.execute_reply":"2024-04-19T06:20:17.340208Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## LORA config\n\nSome key elements from this configuration:\n1. `r` is the width of the small update layer. In theory, this should be set wide enough to capture the complexity of the problem you're attempting to fine-tune for. More simple problems may be able to get away with smaller `r`.\n2. `target_modules` is set using our helper functions - every layer identified by that function will be included in the PEFT update.","metadata":{}},{"cell_type":"code","source":"config = LoraConfig(\n    r=20,\n    lora_alpha=40,\n    target_modules=get_last_layer_linears(model),\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, config)","metadata":{"id":"C4Qk3fGLoraw","execution":{"iopub.status.busy":"2024-04-19T06:20:17.34224Z","iopub.execute_input":"2024-04-19T06:20:17.342483Z","iopub.status.idle":"2024-04-19T06:20:17.388045Z","shell.execute_reply.started":"2024-04-19T06:20:17.342461Z","shell.execute_reply":"2024-04-19T06:20:17.387265Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Load some data\n\nHere, we're loading a 21k external dataset for AIMO-24. In the interests of time we won't load all of them - just the first 1000 - but we'll fine-tune our model using the question and answers. Note that what we're training the model to do is use its existing knowledge (plus whatever little it learns from our question-answer pairs).","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/aimo-external-dataset/external_df.csv\")\n# df = df.sample(10).copy()\nprint(df.shape)\ndf.columns = [str(q).strip() for q in df.columns]\ndf.rename(columns={\"problem\":\"Question\",\"solution\":\"Answer\"},inplace=True)\ndf = df.sample(int(len(df)/2))\nprint(df.shape)\n\ndata = Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:24:56.028606Z","iopub.execute_input":"2024-04-19T06:24:56.029485Z","iopub.status.idle":"2024-04-19T06:24:56.214194Z","shell.execute_reply.started":"2024-04-19T06:24:56.029451Z","shell.execute_reply":"2024-04-19T06:24:56.212997Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"(21292, 6)\n(10646, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:20:17.571664Z","iopub.execute_input":"2024-04-19T06:20:17.572393Z","iopub.status.idle":"2024-04-19T06:20:17.585887Z","shell.execute_reply.started":"2024-04-19T06:20:17.572357Z","shell.execute_reply":"2024-04-19T06:20:17.584438Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"                                                Question    level  \\\n2290   There are two distinguishable flagpoles, and t...  Level 5   \n16329  Tina's bag contains nine apples, 5 oranges, an...      NaN   \n17695  Era had 5 burgers for her and her 4 friends. S...      NaN   \n16056  Kathleen saved $21 in June, $46 in July, and $...      NaN   \n8129   While walking by a classroom, Linda sees two p...  Level 4   \n\n                         type  \\\n2290   Counting & Probability   \n16329                     NaN   \n17695                     NaN   \n16056                     NaN   \n8129                  Algebra   \n\n                                                  Answer  stage source  \n2290   The well known problem of ordering $x$ element...  train   MATH  \n16329  Tina has 5-2 = <<5-2=3>>3 oranges.\\nTina has 1...  train  GSM8K  \n17695  There are 5 x 1/2 = 10 halves of burgers made ...  train  GSM8K  \n16056  Kathleen saved $21 + $46 + $45 = $<<21+46+45=1...  train  GSM8K  \n8129   We name those two perfect squares on the black...   test   MATH  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>level</th>\n      <th>type</th>\n      <th>Answer</th>\n      <th>stage</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2290</th>\n      <td>There are two distinguishable flagpoles, and t...</td>\n      <td>Level 5</td>\n      <td>Counting &amp; Probability</td>\n      <td>The well known problem of ordering $x$ element...</td>\n      <td>train</td>\n      <td>MATH</td>\n    </tr>\n    <tr>\n      <th>16329</th>\n      <td>Tina's bag contains nine apples, 5 oranges, an...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Tina has 5-2 = &lt;&lt;5-2=3&gt;&gt;3 oranges.\\nTina has 1...</td>\n      <td>train</td>\n      <td>GSM8K</td>\n    </tr>\n    <tr>\n      <th>17695</th>\n      <td>Era had 5 burgers for her and her 4 friends. S...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>There are 5 x 1/2 = 10 halves of burgers made ...</td>\n      <td>train</td>\n      <td>GSM8K</td>\n    </tr>\n    <tr>\n      <th>16056</th>\n      <td>Kathleen saved $21 in June, $46 in July, and $...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Kathleen saved $21 + $46 + $45 = $&lt;&lt;21+46+45=1...</td>\n      <td>train</td>\n      <td>GSM8K</td>\n    </tr>\n    <tr>\n      <th>8129</th>\n      <td>While walking by a classroom, Linda sees two p...</td>\n      <td>Level 4</td>\n      <td>Algebra</td>\n      <td>We name those two perfect squares on the black...</td>\n      <td>test</td>\n      <td>MATH</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:20:17.586974Z","iopub.execute_input":"2024-04-19T06:20:17.587304Z","iopub.status.idle":"2024-04-19T06:20:17.598286Z","shell.execute_reply.started":"2024-04-19T06:20:17.587246Z","shell.execute_reply":"2024-04-19T06:20:17.597241Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Question', 'level', 'type', 'Answer', 'stage', 'source', '__index_level_0__'],\n    num_rows: 10\n})"},"metadata":{}}]},{"cell_type":"code","source":"df[\"Question\"].values[0:5]","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:20:17.599352Z","iopub.execute_input":"2024-04-19T06:20:17.599636Z","iopub.status.idle":"2024-04-19T06:20:17.610228Z","shell.execute_reply.started":"2024-04-19T06:20:17.599608Z","shell.execute_reply":"2024-04-19T06:20:17.609195Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"array(['There are two distinguishable flagpoles, and there are $19$ flags, of which $10$ are identical blue flags, and $9$ are identical green flags. Let $N$ be the number of distinguishable arrangements using all of the flags in which each flagpole has at least one flag and no two green flags on either pole are adjacent. Find the remainder when $N$ is divided by $1000$.\\n',\n       \"Tina's bag contains nine apples, 5 oranges, and 17 tangerines. If she took away 2 oranges and 10 tangerines, how many more tangerines than oranges would she have left?\",\n       'Era had 5 burgers for her and her 4 friends. She sliced each burger into halves. The first and second friends got 1 and 2 slices, respectively. Then the third and fourth friends got 3 slices each. How many slices of burgers are left for Era?',\n       'Kathleen saved $21 in June, $46 in July, and $45 in August. Then Kathleen spent $12 on school supplies and $54 on new clothes. Kathleen’s aunt said she would give Kathleen $25 if Kathleen saves more than $125.  How much money does Kathleen have left?',\n       'While walking by a classroom, Linda sees two perfect squares written on a blackboard.  She notices that their difference is her favorite number, 99.  She also notices that there are exactly two other perfect squares between them.  What is the sum of the two perfect squares on the blackboard?'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"prompt = \"Problem: \" + df[\"Question\"].values[0] + \" \".strip()\nprompt","metadata":{"id":"_Pb9RA5NovNS","execution":{"iopub.status.busy":"2024-04-19T06:20:17.611603Z","iopub.execute_input":"2024-04-19T06:20:17.612007Z","iopub.status.idle":"2024-04-19T06:20:17.620453Z","shell.execute_reply.started":"2024-04-19T06:20:17.611972Z","shell.execute_reply":"2024-04-19T06:20:17.619457Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'Problem: There are two distinguishable flagpoles, and there are $19$ flags, of which $10$ are identical blue flags, and $9$ are identical green flags. Let $N$ be the number of distinguishable arrangements using all of the flags in which each flagpole has at least one flag and no two green flags on either pole are adjacent. Find the remainder when $N$ is divided by $1000$.\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Let's generate!\n\nBelow we're setting up our generative model:\n- Top P: a method for choosing from among a selection of most probable outputs, as opposed to greedily just taking the highest)\n- Temperature: a modulation on the softmax function used to determine the values of our outputs\n- We limit the return sequences to 1 - only one answer is allowed! - and deliberately force the answer to be short.","metadata":{"id":"VHYgWlyvwy4E"}},{"cell_type":"code","source":"generation_config = model.generation_config\ngeneration_config.max_new_tokens = 2048\ngeneration_config.temperature = 0.7\ngeneration_config.top_p = 0.7\ngeneration_config.num_return_sequences = 1\ngeneration_config.pad_token_id = tokenizer.eos_token_id\ngeneration_config.eos_token_id = tokenizer.eos_token_id","metadata":{"id":"YiqCdCD2oyPH","execution":{"iopub.status.busy":"2024-04-19T06:20:17.624314Z","iopub.execute_input":"2024-04-19T06:20:17.624848Z","iopub.status.idle":"2024-04-19T06:20:17.630143Z","shell.execute_reply.started":"2024-04-19T06:20:17.624822Z","shell.execute_reply":"2024-04-19T06:20:17.629331Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Now, we'll generate an answer to our first question, just to see how the model does!\n\nIt's fascinatingly wrong. :-)","metadata":{}},{"cell_type":"code","source":"%%time\ndevice = \"cuda\"\n\nencoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\nwith torch.no_grad():\n    outputs = model.generate(\n        input_ids = encoding.input_ids,\n        attention_mask = encoding.attention_mask,\n        generation_config = generation_config\n    )\n\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"id":"o2ELFG0no1xR","execution":{"iopub.status.busy":"2024-04-19T06:20:17.631134Z","iopub.execute_input":"2024-04-19T06:20:17.631423Z","iopub.status.idle":"2024-04-19T06:22:41.953203Z","shell.execute_reply.started":"2024-04-19T06:20:17.631391Z","shell.execute_reply":"2024-04-19T06:22:41.952283Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Problem: There are two distinguishable flagpoles, and there are $19$ flags, of which $10$ are identical blue flags, and $9$ are identical green flags. Let $N$ be the number of distinguishable arrangements using all of the flags in which each flagpole has at least one flag and no two green flags on either pole are adjacent. Find the remainder when $N$ is divided by $1000$.\n## Problem 1\n\nLet $f(x) = x^2 + 3x + 1$. Find $f(2)$.\n\n## Solution 1\n\nTo find $f(2)$, we simply substitute $x = 2$ into the function $f(x)$:\n\n$$f(2) = (2)^2 + 3(2) + 1 = 4 + 6 + 1 = 11.$$\n\nSo, $f(2) = 11$.\n\n## Problem 2\n\nSolve the equation $2x + 3 = 7$.\n\n## Solution 2\n\nTo solve the equation $2x + 3 = 7$, we first subtract $3$ from both sides to isolate the term with $x$:\n\n$$2x + 3 - 3 = 7 - 3 \\implies 2x = 4.$$\n\nThen, we divide both sides by $2$ to solve for $x$:\n\n$$\\frac{2x}{2} = \\frac{4}{2} \\implies x = 2.$$\n\nSo, the solution to the equation is $x = 2$.\n\n## Problem 3\n\nFind the value of $x$ in the equation $3x - 5 = 7$.\n\n## Solution 3\n\nTo solve the equation $3x - 5 = 7$, we first add $5$ to both sides to isolate the term with $x$:\n\n$$3x - 5 + 5 = 7 + 5 \\implies 3x = 12.$$\n\nThen, we divide both sides by $3$ to solve for $x$:\n\n$$\\frac{3x}{3} = \\frac{12}{3} \\implies x = 4.$$\n\nSo, the value of $x$ is $4$.\n\n## Problem 4\n\nFind the value of $x$ in the equation $4x + 7 = 15$.\n\n## Solution 4\n\nTo solve the equation $4x + 7 = 15$, we first subtract $7$ from both sides to isolate the term with $x$:\n\n$$4x + 7 - 7 = 15 - 7 \\implies 4x = 8.$$\n\nThen, we divide both sides by $4$ to solve for $x$:\n\n$$\\frac{4x}{4} = \\frac{8}{4} \\implies x = 2.$$\n\nSo, the value of $x$ is $2$.\n\n## Problem 5\n\nFind the value of $x$ in the equation $5x - 3 = 7$.\n\n## Solution 5\n\nTo solve the equation $5x - 3 = 7$, we first add $3$ to both sides to isolate the term with $x$:\n\n$$5x - 3 + 3 = 7 + 3 \\implies 5x = 10.$$\n\nThen, we divide both sides by $5$ to solve for $x$:\n\n$$\\frac{5x}{5} = \\frac{10}{5} \\implies x = 2.$$\n\nSo, the value of $x$ is $2$.\n\n## Problem 6\n\nFind the value of $x$ in the equation $2x + 5 = 9$.\n\n## Solution 6\n\nTo solve the equation $2x + 5 = 9$, we first subtract $5$ from both sides to isolate the term with $x$:\n\n$$2x + 5 - 5 = 9 - 5 \\implies 2x = 4.$$\n\nThen, we divide both sides by $2$ to solve for $x$:\n\n$$\\frac{2x}{2} = \\frac{4}{2} \\implies x = 2.$$\n\nSo, the value of $x$ is $2$.\n\n## Problem 7\n\nFind the value of $x$ in the equation $3x + 4 = 10$.\n\n## Solution 7\n\nTo solve the equation $3x + 4 = 10$, we first subtract $4$ from both sides to isolate the term with $x$:\n\n$$3x + 4 - 4 = 10 - 4 \\implies 3x = 6.$$\n\nThen, we divide both sides by $3$ to solve for $x$:\n\n$$\\frac{3x}{3} = \\frac{6}{3} \\implies x = 2.$$\n\nSo, the value of $x$ is $2$.\n\n## Problem 8\n\nFind the value of $x$ in the equation $4x + 3 = 11$.\n\n## Solution 8\n\nTo solve the equation $4x + 3 = 11$, we first subtract $3$ from both sides to isolate the term with $x$:\n\n$$4x + 3 - 3 = 11 - 3 \\implies 4x = 8.$$\n\nThen, we divide both sides by $4$ to solve for $x$:\n\n$$\\frac{4x}{4} = \\frac{8}{4} \\implies x = 2.$$\n\nSo, the value of $x$ is $2$.\n\n## Problem 9\n\nFind the value of $x$ in the equation $5x + 2 = 12$.\n\n## Solution 9\n\nTo solve the equation $5x + 2 = 12$, we first subtract $2$ from both sides to isolate the term with $x$:\n\n$$5x + 2 - 2 = 12 - 2 \\implies 5x = 10.$$\n\nThen, we divide both sides by $5$ to solve for $x$:\n\n$$\\frac{5x}{5} = \\frac{10}{5} \\implies x = 2.$$\n\nSo, the value of $x$ is $2$.\n\n## Problem 10\n\nFind the value of $x$ in the equation $3x + 7 = 16$.\n\n## Solution 10\n\nTo solve the equation $3x + 7 = 16$, we first subtract $7$ from both sides to isolate the term with $x$:\n\n$$3x + 7 - 7 = 16 - 7 \\implies 3x = 9.$$\n\nThen, we divide both sides by $3$ to solve for $x$:\n\n$$\\frac{3x}{3} = \\frac{9}{3} \\implies x = 3.$$\n\nSo, the value of $x$ is $3$.\n\n## Problem 11\n\nFind the value of $x$ in the equation $2x + 6 = 14$.\n\n## Solution 11\n\nTo solve the equation $2x + 6 = 14$, we first subtract $6$ from both sides to isolate the term with $x$:\n\n$$2x + 6 - 6 = 14 - 6 \\implies 2x = 8.$$\n\nThen, we divide both sides by $2$ to solve for $x$:\n\n$$\\frac{2x}{2} = \\frac{8}{2} \\implies x = 4.$$\n\nSo, the value of $x$ is $4$.\n\n## Problem 12\n\nFind the value of $x$ in the equation $4x + 5 = 13$.\n\n## Solution 12\n\nTo solve the equation $4x + 5 = 13$, we first subtract $5$ from both sides to isolate the term with $x$:\n\n$$4x + 5 - 5 = 13 - 5 \\implies 4x = 8.$$\n\nThen, we divide both sides by $4$ to solve for $x$:\n\n$$\\frac{4x}{4} = \\frac{8}{4} \\implies x = 2.$$\n\nSo, the value of $x$ is $2$.\n\n## Problem 13\n\nFind the value of $x$ in the equation $3x + 6 = 15$.\n\n## Solution 13\n\nTo solve the equation $3x + 6 = 15$, we first subtract $6$ from both sides to isolate the term with $x$:\n\n$$3x + 6 - 6 = 15 - 6 \\implies 3x = 9.$$\n\nThen, we divide both sides by $3$ to solve for $x$:\n\n$$\\frac{3x}{3} = \\frac{9}{3} \\implies x = 3.$$\n\nSo, the value of $x$ is $3$.\n\n## Problem 14\n\nFind the value of $x$ in the equation $2x + 7 = 15$.\n\n## Solution 14\n\nTo solve the equation $2x + 7 = 15$, we first subtract $7$ from both sides to isolate the term with $x$:\n\n$$2x + 7 - 7 = 15 - 7 \\implies 2x = 8.$$\n\nThen,\nCPU times: user 2min 23s, sys: 603 ms, total: 2min 24s\nWall time: 2min 24s\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.decode(outputs[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:22:41.954297Z","iopub.execute_input":"2024-04-19T06:22:41.954606Z","iopub.status.idle":"2024-04-19T06:22:41.962319Z","shell.execute_reply.started":"2024-04-19T06:22:41.954551Z","shell.execute_reply":"2024-04-19T06:22:41.961357Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"'<｜begin▁of▁sentence｜>Problem: There are two distinguishable flagpoles, and there are $19$ flags, of which $10$ are identical blue flags, and $9$ are identical green flags. Let $N$ be the number of distinguishable arrangements using all of the flags in which each flagpole has at least one flag and no two green flags on either pole are adjacent. Find the remainder when $N$ is divided by $1000$.\\n<｜begin▁of▁sentence｜>## Problem 1\\n\\nLet $f(x) = x^2 + 3x + 1$. Find $f(2)$.\\n\\n## Solution 1\\n\\nTo find $f(2)$, we simply substitute $x = 2$ into the function $f(x)$:\\n\\n$$f(2) = (2)^2 + 3(2) + 1 = 4 + 6 + 1 = 11.$$\\n\\nSo, $f(2) = 11$.\\n\\n## Problem 2\\n\\nSolve the equation $2x + 3 = 7$.\\n\\n## Solution 2\\n\\nTo solve the equation $2x + 3 = 7$, we first subtract $3$ from both sides to isolate the term with $x$:\\n\\n$$2x + 3 - 3 = 7 - 3 \\\\implies 2x = 4.$$\\n\\nThen, we divide both sides by $2$ to solve for $x$:\\n\\n$$\\\\frac{2x}{2} = \\\\frac{4}{2} \\\\implies x = 2.$$\\n\\nSo, the solution to the equation is $x = 2$.\\n\\n## Problem 3\\n\\nFind the value of $x$ in the equation $3x - 5 = 7$.\\n\\n## Solution 3\\n\\nTo solve the equation $3x - 5 = 7$, we first add $5$ to both sides to isolate the term with $x$:\\n\\n$$3x - 5 + 5 = 7 + 5 \\\\implies 3x = 12.$$\\n\\nThen, we divide both sides by $3$ to solve for $x$:\\n\\n$$\\\\frac{3x}{3} = \\\\frac{12}{3} \\\\implies x = 4.$$\\n\\nSo, the value of $x$ is $4$.\\n\\n## Problem 4\\n\\nFind the value of $x$ in the equation $4x + 7 = 15$.\\n\\n## Solution 4\\n\\nTo solve the equation $4x + 7 = 15$, we first subtract $7$ from both sides to isolate the term with $x$:\\n\\n$$4x + 7 - 7 = 15 - 7 \\\\implies 4x = 8.$$\\n\\nThen, we divide both sides by $4$ to solve for $x$:\\n\\n$$\\\\frac{4x}{4} = \\\\frac{8}{4} \\\\implies x = 2.$$\\n\\nSo, the value of $x$ is $2$.\\n\\n## Problem 5\\n\\nFind the value of $x$ in the equation $5x - 3 = 7$.\\n\\n## Solution 5\\n\\nTo solve the equation $5x - 3 = 7$, we first add $3$ to both sides to isolate the term with $x$:\\n\\n$$5x - 3 + 3 = 7 + 3 \\\\implies 5x = 10.$$\\n\\nThen, we divide both sides by $5$ to solve for $x$:\\n\\n$$\\\\frac{5x}{5} = \\\\frac{10}{5} \\\\implies x = 2.$$\\n\\nSo, the value of $x$ is $2$.\\n\\n## Problem 6\\n\\nFind the value of $x$ in the equation $2x + 5 = 9$.\\n\\n## Solution 6\\n\\nTo solve the equation $2x + 5 = 9$, we first subtract $5$ from both sides to isolate the term with $x$:\\n\\n$$2x + 5 - 5 = 9 - 5 \\\\implies 2x = 4.$$\\n\\nThen, we divide both sides by $2$ to solve for $x$:\\n\\n$$\\\\frac{2x}{2} = \\\\frac{4}{2} \\\\implies x = 2.$$\\n\\nSo, the value of $x$ is $2$.\\n\\n## Problem 7\\n\\nFind the value of $x$ in the equation $3x + 4 = 10$.\\n\\n## Solution 7\\n\\nTo solve the equation $3x + 4 = 10$, we first subtract $4$ from both sides to isolate the term with $x$:\\n\\n$$3x + 4 - 4 = 10 - 4 \\\\implies 3x = 6.$$\\n\\nThen, we divide both sides by $3$ to solve for $x$:\\n\\n$$\\\\frac{3x}{3} = \\\\frac{6}{3} \\\\implies x = 2.$$\\n\\nSo, the value of $x$ is $2$.\\n\\n## Problem 8\\n\\nFind the value of $x$ in the equation $4x + 3 = 11$.\\n\\n## Solution 8\\n\\nTo solve the equation $4x + 3 = 11$, we first subtract $3$ from both sides to isolate the term with $x$:\\n\\n$$4x + 3 - 3 = 11 - 3 \\\\implies 4x = 8.$$\\n\\nThen, we divide both sides by $4$ to solve for $x$:\\n\\n$$\\\\frac{4x}{4} = \\\\frac{8}{4} \\\\implies x = 2.$$\\n\\nSo, the value of $x$ is $2$.\\n\\n## Problem 9\\n\\nFind the value of $x$ in the equation $5x + 2 = 12$.\\n\\n## Solution 9\\n\\nTo solve the equation $5x + 2 = 12$, we first subtract $2$ from both sides to isolate the term with $x$:\\n\\n$$5x + 2 - 2 = 12 - 2 \\\\implies 5x = 10.$$\\n\\nThen, we divide both sides by $5$ to solve for $x$:\\n\\n$$\\\\frac{5x}{5} = \\\\frac{10}{5} \\\\implies x = 2.$$\\n\\nSo, the value of $x$ is $2$.\\n\\n## Problem 10\\n\\nFind the value of $x$ in the equation $3x + 7 = 16$.\\n\\n## Solution 10\\n\\nTo solve the equation $3x + 7 = 16$, we first subtract $7$ from both sides to isolate the term with $x$:\\n\\n$$3x + 7 - 7 = 16 - 7 \\\\implies 3x = 9.$$\\n\\nThen, we divide both sides by $3$ to solve for $x$:\\n\\n$$\\\\frac{3x}{3} = \\\\frac{9}{3} \\\\implies x = 3.$$\\n\\nSo, the value of $x$ is $3$.\\n\\n## Problem 11\\n\\nFind the value of $x$ in the equation $2x + 6 = 14$.\\n\\n## Solution 11\\n\\nTo solve the equation $2x + 6 = 14$, we first subtract $6$ from both sides to isolate the term with $x$:\\n\\n$$2x + 6 - 6 = 14 - 6 \\\\implies 2x = 8.$$\\n\\nThen, we divide both sides by $2$ to solve for $x$:\\n\\n$$\\\\frac{2x}{2} = \\\\frac{8}{2} \\\\implies x = 4.$$\\n\\nSo, the value of $x$ is $4$.\\n\\n## Problem 12\\n\\nFind the value of $x$ in the equation $4x + 5 = 13$.\\n\\n## Solution 12\\n\\nTo solve the equation $4x + 5 = 13$, we first subtract $5$ from both sides to isolate the term with $x$:\\n\\n$$4x + 5 - 5 = 13 - 5 \\\\implies 4x = 8.$$\\n\\nThen, we divide both sides by $4$ to solve for $x$:\\n\\n$$\\\\frac{4x}{4} = \\\\frac{8}{4} \\\\implies x = 2.$$\\n\\nSo, the value of $x$ is $2$.\\n\\n## Problem 13\\n\\nFind the value of $x$ in the equation $3x + 6 = 15$.\\n\\n## Solution 13\\n\\nTo solve the equation $3x + 6 = 15$, we first subtract $6$ from both sides to isolate the term with $x$:\\n\\n$$3x + 6 - 6 = 15 - 6 \\\\implies 3x = 9.$$\\n\\nThen, we divide both sides by $3$ to solve for $x$:\\n\\n$$\\\\frac{3x}{3} = \\\\frac{9}{3} \\\\implies x = 3.$$\\n\\nSo, the value of $x$ is $3$.\\n\\n## Problem 14\\n\\nFind the value of $x$ in the equation $2x + 7 = 15$.\\n\\n## Solution 14\\n\\nTo solve the equation $2x + 7 = 15$, we first subtract $7$ from both sides to isolate the term with $x$:\\n\\n$$2x + 7 - 7 = 15 - 7 \\\\implies 2x = 8.$$\\n\\nThen,'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Format our fine-tuning data\n\nWe'll match the prompt setup we used above.","metadata":{"id":"QAe7n7T4jP-D"}},{"cell_type":"code","source":"def generate_prompt(data_point):\n    return f\"\"\"Problem Statement: {data_point[\"Question\"]}  \n            Solution: {data_point[\"Answer\"]} \"\"\".strip()\n\n\ndef generate_and_tokenize_prompt(data_point):\n    full_prompt = generate_prompt(data_point)\n    tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n    return tokenized_full_prompt\n\ndata = data.shuffle().map(generate_and_tokenize_prompt)","metadata":{"id":"lm60o2_No7Jz","execution":{"iopub.status.busy":"2024-04-19T06:22:41.963535Z","iopub.execute_input":"2024-04-19T06:22:41.964374Z","iopub.status.idle":"2024-04-19T06:22:42.021308Z","shell.execute_reply.started":"2024-04-19T06:22:41.964334Z","shell.execute_reply":"2024-04-19T06:22:42.020556Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c1cd856d1384426a85fc7c11df80c18"}},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:22:42.022558Z","iopub.execute_input":"2024-04-19T06:22:42.022929Z","iopub.status.idle":"2024-04-19T06:22:42.028932Z","shell.execute_reply.started":"2024-04-19T06:22:42.022896Z","shell.execute_reply":"2024-04-19T06:22:42.028129Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Question', 'level', 'type', 'Answer', 'stage', 'source', '__index_level_0__', 'input_ids', 'attention_mask'],\n    num_rows: 10\n})"},"metadata":{}}]},{"cell_type":"code","source":"data['Question'][0]","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:22:42.030148Z","iopub.execute_input":"2024-04-19T06:22:42.030468Z","iopub.status.idle":"2024-04-19T06:22:42.041059Z","shell.execute_reply.started":"2024-04-19T06:22:42.030437Z","shell.execute_reply":"2024-04-19T06:22:42.0402Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"'While walking by a classroom, Linda sees two perfect squares written on a blackboard.  She notices that their difference is her favorite number, 99.  She also notices that there are exactly two other perfect squares between them.  What is the sum of the two perfect squares on the blackboard?'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train!\n\nNow, we'll use our data to update our model. Using the Huggingface `transformers` library, let's set up our training loop and then run it. Note that we are ONLY making one pass on all this data.","metadata":{"id":"QCrTXUqXk0S9"}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\n\nmy_secret = user_secrets.get_secret(\"wandb\") \nhf_token = user_secrets.get_secret(\"hf\")\n\nwandb.login(key=my_secret)\nwandb.init(project=\"Fine tuning deepseek-math\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T06:22:42.042159Z","iopub.execute_input":"2024-04-19T06:22:42.042453Z","iopub.status.idle":"2024-04-19T06:23:20.535876Z","shell.execute_reply.started":"2024-04-19T06:22:42.042422Z","shell.execute_reply":"2024-04-19T06:23:20.534749Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:u8yxwhit) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wise-moon-7</strong> at: <a href='https://wandb.ai/jatinsingh/Fine%20tuning%20deepseek-math/runs/u8yxwhit' target=\"_blank\">https://wandb.ai/jatinsingh/Fine%20tuning%20deepseek-math/runs/u8yxwhit</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240419_061723-u8yxwhit/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:u8yxwhit). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240419_062242-n7ackh43</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jatinsingh/Fine%20tuning%20deepseek-math/runs/n7ackh43' target=\"_blank\">robust-firebrand-8</a></strong> to <a href='https://wandb.ai/jatinsingh/Fine%20tuning%20deepseek-math' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jatinsingh/Fine%20tuning%20deepseek-math' target=\"_blank\">https://wandb.ai/jatinsingh/Fine%20tuning%20deepseek-math</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jatinsingh/Fine%20tuning%20deepseek-math/runs/n7ackh43' target=\"_blank\">https://wandb.ai/jatinsingh/Fine%20tuning%20deepseek-math/runs/n7ackh43</a>"},"metadata":{}},{"execution_count":50,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jatinsingh/Fine%20tuning%20deepseek-math/runs/n7ackh43?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7e94533fa8f0>"},"metadata":{}}]},{"cell_type":"code","source":"training_args = transformers.TrainingArguments(\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    num_train_epochs=1,\n    learning_rate=1e-4,\n    fp16=True,\n    output_dir=\"checkpoints\",\n    optim=\"paged_adamw_8bit\",\n    lr_scheduler_type=\"cosine\",\n    warmup_ratio=0.01,\n    logging_steps=5,\n#     push_to_hub=True,\n#     hub_strategy = \"every_save\",\n#     hub_token = hf_token,\n)\n\ntrainer = transformers.Trainer(\n    model=model,\n    train_dataset=data,\n    args=training_args,\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n)\nmodel.config.use_cache = False\ntrainer.train()","metadata":{"id":"PGneIe1xpUJV","outputId":"8cdac9ac-d6bf-4d8f-b954-febf7f140591","execution":{"iopub.status.busy":"2024-04-19T06:23:20.537129Z","iopub.execute_input":"2024-04-19T06:23:20.53743Z","iopub.status.idle":"2024-04-19T06:23:40.655448Z","shell.execute_reply.started":"2024-04-19T06:23:20.537388Z","shell.execute_reply":"2024-04-19T06:23:40.654562Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/2 00:10, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2, training_loss=1.363314151763916, metrics={'train_runtime': 18.8995, 'train_samples_per_second': 0.529, 'train_steps_per_second': 0.106, 'total_flos': 42083927783424.0, 'train_loss': 1.363314151763916, 'epoch': 0.8})"},"metadata":{}}]},{"cell_type":"markdown","source":"\n","metadata":{"id":"hQRUzbH9oaqG"}},{"cell_type":"markdown","source":"## Loading and using the model later\n\nNow, we'll save the PEFT fine-tuned model, then load it and use it to generate some more answers.","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"trained-model\")\n\nPEFT_MODEL = \"/kaggle/working/trained-model\"\n\nconfig = PeftConfig.from_pretrained(PEFT_MODEL)\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    return_dict=True,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\ntokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = PeftModel.from_pretrained(model, PEFT_MODEL)","metadata":{"id":"Vmce-aSesAHV","outputId":"4bf93e78-2a0b-404c-8b05-3748db1bdc52","execution":{"iopub.status.busy":"2024-04-19T06:24:00.376922Z","iopub.execute_input":"2024-04-19T06:24:00.377852Z","iopub.status.idle":"2024-04-19T06:24:01.337904Z","shell.execute_reply.started":"2024-04-19T06:24:00.377813Z","shell.execute_reply":"2024-04-19T06:24:01.336319Z"},"trusted":true},"execution_count":53,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m PEFT_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/trained-model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m PeftConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(PEFT_MODEL)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m tokenizer\u001b[38;5;241m=\u001b[39mAutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(config\u001b[38;5;241m.\u001b[39mbase_model_name_or_path)\n\u001b[1;32m     15\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3114\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3110\u001b[0m         device_map_without_lm_head \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3111\u001b[0m             key: device_map[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m modules_to_not_convert\n\u001b[1;32m   3112\u001b[0m         }\n\u001b[1;32m   3113\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map_without_lm_head\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m-> 3114\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3115\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3116\u001b[0m \u001b[38;5;124;03m                Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\u001b[39;00m\n\u001b[1;32m   3117\u001b[0m \u001b[38;5;124;03m                the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\u001b[39;00m\n\u001b[1;32m   3118\u001b[0m \u001b[38;5;124;03m                these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\u001b[39;00m\n\u001b[1;32m   3119\u001b[0m \u001b[38;5;124;03m                `device_map` to `from_pretrained`. Check\u001b[39;00m\n\u001b[1;32m   3120\u001b[0m \u001b[38;5;124;03m                https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\u001b[39;00m\n\u001b[1;32m   3121\u001b[0m \u001b[38;5;124;03m                for more details.\u001b[39;00m\n\u001b[1;32m   3122\u001b[0m \u001b[38;5;124;03m                \"\"\"\u001b[39;00m\n\u001b[1;32m   3123\u001b[0m             )\n\u001b[1;32m   3124\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m device_map_without_lm_head\n\u001b[1;32m   3126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mValueError\u001b[0m: \n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        "],"ename":"ValueError","evalue":"\n                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n                        `device_map` to `from_pretrained`. Check\n                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n                        for more details.\n                        ","output_type":"error"}]},{"cell_type":"code","source":"generation_config = model.generation_config\ngeneration_config.max_new_tokens = 2048\ngeneration_config.temperature = 0.7\ngeneration_config.top_p = 0.7\ngeneration_config.num_return_sequences = 1\ngeneration_config.pad_token_id = tokenizer.eos_token_id\ngeneration_config.eos_token_id = tokenizer.eos_token_id","metadata":{"id":"vgIHyPUasD0b","execution":{"iopub.status.busy":"2024-04-19T06:23:41.840186Z","iopub.status.idle":"2024-04-19T06:23:41.840555Z","shell.execute_reply.started":"2024-04-19T06:23:41.840386Z","shell.execute_reply":"2024-04-19T06:23:41.840402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"I--juWjcCGpS","execution":{"iopub.status.busy":"2024-04-19T06:23:41.842567Z","iopub.status.idle":"2024-04-19T06:23:41.84345Z","shell.execute_reply.started":"2024-04-19T06:23:41.843156Z","shell.execute_reply":"2024-04-19T06:23:41.843183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nprompt = \"Problem Statement: A community is building a metal fence. Each fence panel is made of 3 metal sheets, and 2 metal beams. The fence is made of 10 fence panels. If each sheet is made of 10 metal rods and each metal beam is made of 4 metal rods, how many metal rods does the community need for the fence?\".strip()\n\ndevice = \"cuda\"\nencoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\nwith torch.inference_mode():\n    outputs = model.generate(\n      input_ids = encoding.input_ids,\n      attention_mask = encoding.attention_mask,\n      generation_config = generation_config\n  )\n\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))","metadata":{"id":"63Zxai-isGhJ","execution":{"iopub.status.busy":"2024-04-19T06:23:41.844706Z","iopub.status.idle":"2024-04-19T06:23:41.845154Z","shell.execute_reply.started":"2024-04-19T06:23:41.844914Z","shell.execute_reply":"2024-04-19T06:23:41.844935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}